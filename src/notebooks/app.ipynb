{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installing required Libraries"
      ],
      "metadata": {
        "id": "cPHsJDxO4e_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q langchain            # Main orchestrator\n",
        "!pip install -U -q langchain-core      # Core components (Document, BaseRetriever, LLMChain)\n",
        "!pip install -U -q langchain-community # All community loaders, vectorstores\n",
        "!pip install -U -q langchain-openai    # For OpenAI\n",
        "!pip install -U -q langchain-huggingface\n",
        "!pip install -U -q langchain-text-splitters\n",
        "!pip install -U -q langchain-groq\n",
        "!pip install -U -q langchain-together"
      ],
      "metadata": {
        "id": "MAiurKYg1JTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y \\\n",
        "#   langchain langchain-core langchain-community langchain-openai \\\n",
        "#   langchain-text-splitters langchain-huggingface langchain-groq \\\n",
        "#   langchain-together langchain-classic langgraph langgraph-prebuilt"
      ],
      "metadata": {
        "id": "xe18MHR2pQYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \\\n",
        "  \"langchain==1.1.0\" \\\n",
        "  \"langchain-core==1.1.0\" \\\n",
        "  \"langchain-community==0.4.1\" \\\n",
        "  \"langchain-text-splitters==1.0.0\" \\\n",
        "  \"langchain-huggingface==1.1.0\" \\\n",
        "  \"langchain-openai==1.0.0\" \\\n",
        "  \"langchain-groq==1.1.0\"\n",
        "\n",
        "!pip install -U chromadb faiss-cpu sentence-transformers langchain-chroma"
      ],
      "metadata": {
        "id": "kXHXX1ciorfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required Libraries"
      ],
      "metadata": {
        "id": "G_lacH364trk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "# from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_openai import ChatOpenAI # Import ChatOpenAI\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import pandas as pd\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from dotenv import load_dotenv # Corrected import statement\n",
        "from pprint import pprint\n",
        "from google.colab import drive\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "IOLgwRjVpVIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Drive"
      ],
      "metadata": {
        "id": "Sl6xQnt74yzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To do: Connect to google drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lZOO_Ojn--b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the .env file\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "# Access the key\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "eYj0xnhilYQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the embedding model"
      ],
      "metadata": {
        "id": "d8oMeDGH_94j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embedding = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "os25WSzI2ecU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load vector store from disk"
      ],
      "metadata": {
        "id": "D7H7tsoLEBvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "persist_directory = \"/content/drive/MyDrive/chroma_db\"\n",
        "\n",
        "db = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embedding\n",
        ")"
      ],
      "metadata": {
        "id": "5OjgoaqXBPcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the retriever"
      ],
      "metadata": {
        "id": "PbPQHTYvFFFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the retriever\n",
        "retriever = db.as_retriever(\n",
        "search_type=\"mmr\", # (Maximal Marginal Relevance) is a retrieval strategy that balances relevance and diversity, helping avoid redundant results in your retrieved documents.\n",
        "\n",
        "search_kwargs={\n",
        "    'k': 3,\n",
        "    #controls the trade-off between relevance and diversity (difference from already selected docs) — lower values favor diversity, higher values favor relevance.\n",
        "    \"lambda_mult\": 0.25,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "F0kr0J-ByhfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the LLM model\n"
      ],
      "metadata": {
        "id": "9ugbSE0SFNXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    openai_api_key= ,\n",
        "    temperature=0.0\n",
        ")"
      ],
      "metadata": {
        "id": "0xeIG80y67lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the chat prompt template\n",
        "define a strict, context-aware prompt for your Retrieval-Augmented Generation (RAG) pipeline."
      ],
      "metadata": {
        "id": "zQE7eNJnFgpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "\n",
        "template = \"\"\"\n",
        "You are a precise assistant.\n",
        "Use ONLY the context below to answer the question.\n",
        "If the context does not contain the answer, reply EXACTLY with:\n",
        "I do not know\n",
        "\n",
        "Do NOT include any extra text, instructions, or explanations.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1NR8xXlQypQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
        ""
      ],
      "metadata": {
        "id": "98_RjT6DBdTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "gpt_llm_chain = (\n",
        "    {\n",
        "        \"context\": retriever,\n",
        "        \"query\": RunnablePassthrough()\n",
        "    }\n",
        "    | prompt\n",
        "    | gpt_llm\n",
        "    | output_parser\n",
        ")"
      ],
      "metadata": {
        "id": "S_hv0Yd7yzJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define tests"
      ],
      "metadata": {
        "id": "YP0RmDJxsSsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_questions = [\n",
        "    # Elements of Crimes (ICC)\n",
        "    \"What are the elements required to establish genocide by killing under Article 6(a) of the Elements of Crimes?\",\n",
        "    \"According to the general introduction of the Elements of Crimes, how can the existence of intent and knowledge be inferred?\",\n",
        "\n",
        "    # Genocide Convention\n",
        "    \"According to Article 2 of the Genocide Convention, what acts constitute genocide?\",\n",
        "    \"Who can be punished for committing genocide or related acts under Article 4 of the Convention?\",\n",
        "\n",
        "    # Declaration on Protection of Women and Children in Armed Conflict\n",
        "    \"According to the Declaration, what acts committed by belligerents against women and children in military operations or occupied territories are considered criminal?\",\n",
        "    \"What obligations do States have under the Geneva Protocol of 1925 and the Geneva Conventions of 1949 to protect women and children in armed conflicts?\",\n",
        "\n",
        "    # Optional Protocol to CEDAW\n",
        "    \"Under Article 4 of the Protocol, in what circumstances will the Committee declare a communication inadmissible?\",\n",
        "    \"What powers does the Committee have under Article 8 when it receives reliable information about grave or systematic violations of women’s rights?\",\n",
        "\n",
        "    # Convention on the Suppression of Unlawful Acts against Maritime Navigation (Rome, 1988)\n",
        "    \"According to Article 6, under what circumstances must a State Party establish jurisdiction over offences committed against maritime navigation?\",\n",
        "    \"What obligations does Article 10 impose on a State Party if it does not extradite an alleged offender found in its territory?\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "Dppd3PLVoeVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Invoking"
      ],
      "metadata": {
        "id": "gtGyiRuRGC1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio UI"
      ],
      "metadata": {
        "id": "I8-iuS041smz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "220f926e"
      },
      "source": [
        "!pip install gradio -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ef91b0"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "def ask_rag_model(question):\n",
        "    return gpt_llm_chain.invoke(question)\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=ask_rag_model,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter your question here...\"),\n",
        "    outputs=gr.Textbox(lines=10, label=\"Answer\"),\n",
        "    title=\"Human Rights Library\",\n",
        "    description=\"\"\"Welcome to the Human Rights Library!\\n\\nAsk any question about human rights documents. Our intelligent assistant will provide answers based *only* on the available documentation. If the information isn't found within our library, it will simply state 'I do not know' to ensure accuracy and prevent hallucination.\"\"\",\n",
        "    theme=\"soft\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5BteNftQlDW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}